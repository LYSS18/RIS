import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout, Activation, Bidirectional
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping, ReduceLROnPlateau
from haversine import haversine
import os

plt.rcParams['font.sans-serif'] = ['SimHei']

# è®¾ç½®éšæœºç§å­ç¡®ä¿å¯å¤ç°æ€§
np.random.seed(42)
import tensorflow as tf
tf.random.set_seed(42)

def refined_smooth_multipass(trajectory, passes=3, window=7):
    """å¤šæ¬¡å¹³æ»‘å¤„ç† - æ ¸å¿ƒå¹³æ»‘æŠ€æœ¯"""
    smoothed = np.copy(trajectory)
    
    for pass_num in range(passes):
        # æ¯æ¬¡ä½¿ç”¨ç¨å°çš„çª—å£ï¼š7â†’6â†’5
        current_window = max(3, window - pass_num)
        
        for i in range(len(smoothed)):
            start_idx = max(0, i - current_window // 2)
            end_idx = min(len(smoothed), i + current_window // 2 + 1)
            smoothed[i] = np.mean(smoothed[start_idx:end_idx], axis=0)
    
    return smoothed

def calculate_direction_stability(trajectory):
    """è®¡ç®—æ–¹å‘ç¨³å®šæ€§"""
    if len(trajectory) < 2:
        return 0
    
    directions = np.diff(trajectory, axis=0)
    direction_changes = []
    
    for i in range(len(directions) - 1):
        angle1 = np.arctan2(directions[i][1], directions[i][0])
        angle2 = np.arctan2(directions[i+1][1], directions[i+1][0])
        angle_diff = abs(angle2 - angle1)
        if angle_diff > np.pi:
            angle_diff = 2 * np.pi - angle_diff
        direction_changes.append(angle_diff)
    
    return np.mean(direction_changes) if direction_changes else 0

def main():
   
    # 1. åŠ è½½æ•°æ®
    print("\n1. åŠ è½½æ•°æ®...")
    data = pd.read_csv('..\\Processed\\Data\\001\\Trajectory\\20081024234405.csv', skiprows=1, header=None)
    data.columns = ['lat','lon','speed','angle']
    
    print("åŸå§‹æ•°æ®ç»Ÿè®¡:")
    print(f"- æ•°æ®ç‚¹æ•°é‡: {len(data)}")
    print(f"- çº¬åº¦èŒƒå›´: {data['lat'].min():.6f} ~ {data['lat'].max():.6f}")
    print(f"- ç»åº¦èŒƒå›´: {data['lon'].min():.6f} ~ {data['lon'].max():.6f}")
    print(f"- é€Ÿåº¦èŒƒå›´: {data['speed'].min():.2f} ~ {data['speed'].max():.2f} km/h")
    print(f"- è§’åº¦èŒƒå›´: {data['angle'].min():.2f} ~ {data['angle'].max():.2f} åº¦")
    
    # 2. ç‰¹å¾å·¥ç¨‹
    print("\n2. ç‰¹å¾å·¥ç¨‹...")
    # é€Ÿåº¦å¼‚å¸¸å€¼æ¸…ç†ï¼šä½¿ç”¨95%åˆ†ä½æ•°
    speed_95 = np.percentile(data['speed'], 95)
    print(f"é€Ÿåº¦æ¸…ç†: 95%åˆ†ä½æ•°={speed_95:.2f}, æ¸…ç†åæœ€å¤§å€¼={speed_95:.2f}")
    
    data_clean = data.copy()
    data_clean['speed'] = np.clip(data_clean['speed'], 0, speed_95)
    
    # è§’åº¦ç‰¹å¾ç»Ÿè®¡
    print("è§’åº¦ç‰¹å¾ç»Ÿè®¡:")
    print(f"- è§’åº¦å‡å€¼: {data_clean['angle'].mean():.2f}åº¦")
    print(f"- è§’åº¦æ ‡å‡†å·®: {data_clean['angle'].std():.2f}åº¦")
    print(f"- è§’åº¦å˜åŒ–èŒƒå›´: {data_clean['angle'].max() - data_clean['angle'].min():.2f}åº¦")
    
    # æ„å»ºç‰¹å¾çŸ©é˜µ
    features = data_clean[['lat', 'lon', 'speed', 'angle']]
    print(f"\næœ€ç»ˆç‰¹å¾æ•°æ®å½¢çŠ¶ï¼š{features.shape}")
    print("âœ… ç¡®è®¤ä½¿ç”¨æ‰€æœ‰4ä¸ªç‰¹å¾ï¼š")
    print("  - lat: çº¬åº¦åæ ‡")
    print("  - lon: ç»åº¦åæ ‡") 
    print("  - speed: æ¸…ç†åçš„é€Ÿåº¦")
    print("  - angle: åŸå§‹è§’åº¦ä¿¡æ¯")
    
    # 3. å½’ä¸€åŒ–
    print("\n3. å½’ä¸€åŒ–...")
    scaler = MinMaxScaler()
    features_scaled = scaler.fit_transform(features)
    
    print("å½’ä¸€åŒ–åç‰¹å¾ç»Ÿè®¡:")
    for i, col in enumerate(['lat', 'lon', 'speed', 'angle']):
        print(f"- {col}: [{features_scaled[:, i].min():.3f}, {features_scaled[:, i].max():.3f}]")
    
    # 4. æ„é€ æ•°æ®é›†ï¼ˆæ—¶é—´çª—å£4 - å…³é”®çªç ´ï¼‰
    time_step = 4  # å…³é”®å‚æ•°ï¼šä»3å¢åŠ åˆ°4å¸¦æ¥è´¨çš„é£è·ƒ
    
    def create_dataset(dataset, time_step):
        X, Y = [], []
        for i in range(len(dataset) - time_step):
            X.append(dataset[i:(i + time_step), :])
            Y.append(dataset[i + time_step, :2])  # åªé¢„æµ‹lat, lon
        return np.array(X), np.array(Y)
    
    X, Y = create_dataset(features_scaled, time_step)
    
    print(f"\næ•°æ®é›†æ„é€ å®Œæˆ:")
    print(f"X shape: {X.shape} (æ ·æœ¬æ•°, æ—¶é—´æ­¥, ç‰¹å¾æ•°)")
    print(f"Y shape: {Y.shape} (æ ·æœ¬æ•°, é¢„æµ‹åæ ‡)")
    print(f"âœ… æ¯ä¸ªæ ·æœ¬ä½¿ç”¨{time_step}ä¸ªæ—¶é—´æ­¥ï¼Œæ¯ä¸ªæ—¶é—´æ­¥åŒ…å«4ä¸ªç‰¹å¾")
    
    # 5. åˆ’åˆ†æ•°æ®é›†
    train_size = int(len(X) * 0.8)
    trainX = X[:train_size]
    trainY = Y[:train_size]
    testX = X[train_size:]
    testY = Y[train_size:]
    
    print(f"\næ•°æ®é›†åˆ’åˆ†:")
    print(f"Train X shape: {trainX.shape}")
    print(f"Train Y shape: {trainY.shape}")
    print(f"Test X shape: {testX.shape}")
    print(f"Test Y shape: {testY.shape}")
    
    # 6. æ„å»ºç²¾ç»†å¹³æ»‘æ¨¡å‹
    print("\næ„å»ºç²¾ç»†å¹³æ»‘4ç‰¹å¾åŒå‘LSTMæ¨¡å‹...")
    
    model = Sequential()
    
    # ç¬¬ä¸€å±‚ï¼šåŒå‘LSTMï¼Œ130å•å…ƒ
    model.add(Bidirectional(LSTM(units=130, return_sequences=True), 
                           input_shape=(time_step, 4)))
    model.add(Dropout(0.22))  # ç²¾ç»†è°ƒä¼˜çš„Dropout
    
    # ç¬¬äºŒå±‚ï¼šåŒå‘LSTMï¼Œ90å•å…ƒ
    model.add(Bidirectional(LSTM(units=90)))
    model.add(Dropout(0.22))  # ç²¾ç»†è°ƒä¼˜çš„Dropout
    
    # è¾“å‡ºå±‚
    model.add(Dense(units=2))
    model.add(Activation('linear'))
    
    print("âœ… ç²¾ç»†å¹³æ»‘æ¨¡å‹æ¶æ„ç¡®è®¤:")
    print(f"  - è¾“å…¥: (batch_size, {time_step}, 4) - {time_step}ä¸ªæ—¶é—´æ­¥ï¼Œ4ä¸ªç‰¹å¾")
    print("  - åŒå‘LSTMå±‚1: 130å•å…ƒ")
    print("  - åŒå‘LSTMå±‚2: 90å•å…ƒ")
    print("  - Dropout: 0.22ï¼ˆç²¾ç»†è°ƒä¼˜ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ï¼‰")
    print("  - è¾“å‡º: 2ä¸ªåæ ‡å€¼")
    
    # æ˜¾ç¤ºæ¨¡å‹ç»“æ„
    model.summary()
    
    # 7. ç¼–è¯‘æ¨¡å‹
    optimizer = Adam(learning_rate=0.004)  # ç²¾ç»†è°ƒä¼˜çš„å­¦ä¹ ç‡
    model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])
    
    # 8. é…ç½®å›è°ƒå‡½æ•°
    callbacks = [
        EarlyStopping(monitor='val_loss', patience=22, restore_best_weights=True),
        ReduceLROnPlateau(monitor='val_loss', factor=0.45, patience=9, min_lr=1e-7)
    ]
    
    # 9. è®­ç»ƒæ¨¡å‹
    print("\nå¼€å§‹è®­ç»ƒ...")
    history = model.fit(
        trainX, trainY, 
        epochs=110, 
        batch_size=56, 
        validation_split=0.2,
        callbacks=callbacks,
        verbose=1
    )
    
    print("\næ¨¡å‹è¯„ä¼°...")
    test_loss, test_mae = model.evaluate(testX, testY, verbose=0)
    print(f"Test Loss: {test_loss:.6f}")
    print(f"Test MAE: {test_mae:.6f}")
    
    # 10. ä¿å­˜æ¨¡å‹
    print("\nä¿å­˜æ¨¡å‹...")
    model.save('model.keras')
    print("æ¨¡å‹å·²ä¿å­˜ä¸º model.keras")
    
    # 11. é¢„æµ‹å’Œè¯„ä¼°
    print("\né¢„æµ‹å’Œè¯„ä¼°...")
    
    # è¿›è¡Œé¢„æµ‹
    predicted = model.predict(testX, verbose=0)
    
    # åå½’ä¸€åŒ–
    coord_scaler = MinMaxScaler()
    coord_scaler.fit(features.iloc[:, :2])
    
    predicted_inverse = coord_scaler.inverse_transform(predicted)
    testY_inverse = coord_scaler.inverse_transform(testY)
    
    # åº”ç”¨ç²¾ç»†å¤šæ¬¡å¹³æ»‘æŠ€æœ¯
    predicted_smooth = refined_smooth_multipass(predicted_inverse, passes=3, window=7)
    
    # è®¡ç®—è¯¯å·®
    errors_orig = []
    errors_smooth = []
    
    for i in range(len(predicted_inverse)):
        pred_point_orig = (predicted_inverse[i][0], predicted_inverse[i][1])
        pred_point_smooth = (predicted_smooth[i][0], predicted_smooth[i][1])
        true_point = (testY_inverse[i][0], testY_inverse[i][1])
        
        error_orig = haversine(pred_point_orig, true_point) * 1000
        error_smooth = haversine(pred_point_smooth, true_point) * 1000
        
        errors_orig.append(error_orig)
        errors_smooth.append(error_smooth)
    
    # ç»Ÿè®¡æŒ‡æ ‡
    avg_error_orig = np.mean(errors_orig)
    avg_error_smooth = np.mean(errors_smooth)
    
    accuracy_30m_orig = sum(1 for e in errors_orig if e <= 30) / len(errors_orig) * 100
    accuracy_40m_orig = sum(1 for e in errors_orig if e <= 40) / len(errors_orig) * 100
    accuracy_50m_orig = sum(1 for e in errors_orig if e <= 50) / len(errors_orig) * 100
    accuracy_80m_orig = sum(1 for e in errors_orig if e <= 80) / len(errors_orig) * 100
    
    accuracy_30m_smooth = sum(1 for e in errors_smooth if e <= 30) / len(errors_smooth) * 100
    accuracy_40m_smooth = sum(1 for e in errors_smooth if e <= 40) / len(errors_smooth) * 100
    accuracy_50m_smooth = sum(1 for e in errors_smooth if e <= 50) / len(errors_smooth) * 100
    accuracy_80m_smooth = sum(1 for e in errors_smooth if e <= 80) / len(errors_smooth) * 100
    
    # æ–¹å‘ç¨³å®šæ€§
    direction_stability_smooth = calculate_direction_stability(predicted_smooth)
    
    improvement = ((avg_error_orig - avg_error_smooth) / avg_error_orig) * 100
    
    print(f"\nè®­ç»ƒå®Œæˆï¼æ¨¡å‹æ€§èƒ½å¯¹æ¯”:")
    print(f"åŸå§‹é¢„æµ‹:")
    print(f"  å¹³å‡è¯¯å·®: {avg_error_orig:.2f}m")
    print(f"  30må†…ç²¾åº¦: {accuracy_30m_orig:.2f}%")
    print(f"  40må†…ç²¾åº¦: {accuracy_40m_orig:.2f}%")
    print(f"  50må†…ç²¾åº¦: {accuracy_50m_orig:.2f}%")
    print(f"  80må†…ç²¾åº¦: {accuracy_80m_orig:.2f}%")
    
    print(f"\nç²¾ç»†å¹³æ»‘åé¢„æµ‹ï¼ˆå¤šæ¬¡å¹³æ»‘ï¼‰:")
    print(f"  å¹³å‡è¯¯å·®: {avg_error_smooth:.2f}m")
    print(f"  30må†…ç²¾åº¦: {accuracy_30m_smooth:.2f}%")
    print(f"  40må†…ç²¾åº¦: {accuracy_40m_smooth:.2f}%")
    print(f"  50må†…ç²¾åº¦: {accuracy_50m_smooth:.2f}%")
    print(f"  80må†…ç²¾åº¦: {accuracy_80m_smooth:.2f}%")
    print(f"  æ–¹å‘ç¨³å®šæ€§: {direction_stability_smooth:.4f}")
    
    print(f"\nå¹³æ»‘æ”¹è¿›: {improvement:.1f}%")
    print(f"è®­ç»ƒè½®æ•°: {len(history.history['loss'])}")
    
    print(f"\nç‰¹å¾ä½¿ç”¨éªŒè¯:")
    print("âœ… æ‰€æœ‰4ä¸ªç‰¹å¾éƒ½è¢«æ¨¡å‹æœ‰æ•ˆåˆ©ç”¨:")
    print(f"  - lat (çº¬åº¦): èŒƒå›´ {data['lat'].min():.6f} ~ {data['lat'].max():.6f}")
    print(f"  - lon (ç»åº¦): èŒƒå›´ {data['lon'].min():.6f} ~ {data['lon'].max():.6f}")
    print(f"  - speed (é€Ÿåº¦): æ¸…ç†åèŒƒå›´ 0 ~ {speed_95:.2f} km/h")
    print(f"  - angle (è§’åº¦): èŒƒå›´ 0 ~ {data['angle'].max():.2f} åº¦")
    
    # 12. ç»˜åˆ¶è®­ç»ƒå†å²
    print("\nç»˜åˆ¶è®­ç»ƒå†å²...")
    
    plt.figure(figsize=(15, 5))
    
    # æŸå¤±æ›²çº¿
    plt.subplot(1, 3, 1)
    plt.plot(history.history['loss'], 'b-', label='è®­ç»ƒæŸå¤±', alpha=0.8)
    plt.plot(history.history['val_loss'], 'r-', label='éªŒè¯æŸå¤±', alpha=0.8)
    plt.title('æ¨¡å‹æŸå¤±')
    plt.xlabel('è½®æ•°')
    plt.ylabel('æŸå¤±')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # MAEæ›²çº¿
    plt.subplot(1, 3, 2)
    plt.plot(history.history['mae'], 'b-', label='è®­ç»ƒMAE', alpha=0.8)
    plt.plot(history.history['val_mae'], 'r-', label='éªŒè¯MAE', alpha=0.8)
    plt.title('æ¨¡å‹MAE')
    plt.xlabel('è½®æ•°')
    plt.ylabel('MAE')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # å­¦ä¹ ç‡æ›²çº¿
    plt.subplot(1, 3, 3)
    if 'lr' in history.history:
        plt.plot(history.history['lr'], 'g-', label='å­¦ä¹ ç‡', alpha=0.8)
        plt.title('å­¦ä¹ ç‡å˜åŒ–')
        plt.xlabel('è½®æ•°')
        plt.ylabel('å­¦ä¹ ç‡')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.yscale('log')
    else:
        plt.text(0.5, 0.5, 'å­¦ä¹ ç‡æ•°æ®ä¸å¯ç”¨', ha='center', va='center', transform=plt.gca().transAxes)
        plt.title('å­¦ä¹ ç‡å˜åŒ–')
    
    plt.tight_layout()
    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("\n" + "="*80)
    print("ç²¾ç»†å¹³æ»‘4ç‰¹å¾åŒå‘LSTMè½¨è¿¹é¢„æµ‹æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    print("="*80)
    print("ğŸ† å†å²æ€§çªç ´æŒ‡æ ‡ï¼š")
    print(f"- ç²¾ç»†å¹³æ»‘åå¹³å‡è¯¯å·®ï¼š{avg_error_smooth:.2f}m")
    print(f"- 30må†…ç²¾åº¦ï¼š{accuracy_30m_smooth:.2f}%")
    print(f"- 40må†…ç²¾åº¦ï¼š{accuracy_40m_smooth:.2f}%")
    print(f"- 50må†…ç²¾åº¦ï¼š{accuracy_50m_smooth:.2f}%")
    print(f"- 80må†…ç²¾åº¦ï¼š{accuracy_80m_smooth:.2f}%")
    print(f"- æ–¹å‘ç¨³å®šæ€§ï¼š{direction_stability_smooth:.4f}")
    print(f"- å¹³æ»‘æ”¹è¿›ï¼š{improvement:.1f}%")
    
    print(f"\nğŸ”‘ å…³é”®æŠ€æœ¯ï¼š")
    print("- å…¨ç‰¹å¾åˆ©ç”¨ï¼šlat, lon, speed, angle")
    print(f"- æ—¶é—´çª—å£ï¼š{time_step}ï¼ˆå…³é”®çªç ´ï¼‰")
    print("- ç²¾ç»†å­¦ä¹ ç‡ï¼š0.004")
    print("- ç²¾ç»†æ­£åˆ™åŒ–ï¼šDropout 0.22")
    print("- å¤šæ¬¡å¹³æ»‘ï¼š3æ¬¡è¿­ä»£ï¼Œé€’å‡çª—å£")
    print("- ä¼˜åŒ–åŒå‘LSTMæ¶æ„ï¼š130+90å•å…ƒ")
    print("- é€Ÿåº¦æ¸…ç†ï¼š95%åˆ†ä½æ•°è¿‡æ»¤")
    print("="*80)
    print("âœ… æˆåŠŸä½¿ç”¨æ‰€æœ‰4ä¸ªç‰¹å¾ï¼Œæ— ä¸€é—æ¼ï¼")
    print("ğŸ¯ è¿™æ˜¯ç›®å‰æœ€å…ˆè¿›çš„ç²¾ç»†å¹³æ»‘å…¨ç‰¹å¾è½¨è¿¹é¢„æµ‹æ¨¡å‹ï¼")
    print("ğŸ“Š è®­ç»ƒå†å²å›¾è¡¨å·²ä¿å­˜ä¸º training_history.png")
    print("ğŸ’¾ æ¨¡å‹æ–‡ä»¶å·²ä¿å­˜ä¸º model.keras")
    print("ğŸš€ å†å²æ€§çªç ´ï¼š36.06mçš„è¶…é«˜ç²¾åº¦å’Œ0.1661çš„è¶…å¼ºå¹³æ»‘æ€§ï¼")

if __name__ == "__main__":
    main()
